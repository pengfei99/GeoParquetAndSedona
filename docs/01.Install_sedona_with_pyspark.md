# Sedona



## Install sedona with python/pyspark

Sedona is a framework which can do geospatial calculation. It can work on top of the spark. In this tutorial, we will
show how to make sedona works with pyspark

## Prerequisite

- Install jdk
- Install spark and pyspark.

## Install apache-sedona python API

```shell
# Since Sedona v1.1.0, pyspark is an optional dependency of Sedona Python because spark comes pre-installed on 
# many spark platforms. To install pyspark along with Sedona Python in one go, use the spark extra
pip install apache-sedona[spark]
```

## Prepare sedona-spark jar

Sedona Python needs one additional jar file called `sedona-spark-shaded` or `sedona-spark` to work properly. 
Please make sure you use the correct version for Spark and Scala.

For Spark 3.0 to 3.3 and Scala 2.12, it is called `sedona-spark-shaded-3.0_2.12-1.5.1.jar` or `sedona-spark-3.0_2.12-1.5.1.jar`

For Spark 3.4+ and Scala 2.12, it is called `sedona-spark-shaded-3.4_2.12-1.5.1.jar` or `sedona-spark-3.4_2.12-1.5.1.jar`. 
> If you are using Spark versions higher than 3.4, please replace the 3.4 in artifact names with the corresponding major.minor version numbers.

Another jar is the `geotools-wrapper`

## Create a sedona session without internet
If you don't have internet access, you can import the required jars into your server.
Then create the sedona context with the local jars.

```shell
# build a sedona session offline
jar_folder = Path(r"/home/pengfei/git/PySparkCommonFunc/jars")
jar_list = [str(jar) for jar in jar_folder.iterdir() if jar.is_file()]
jar_path = ",".join(jar_list)

# build a sedona session (sedona = 1.5.1)
config = SedonaContext.builder() \
    .appName("Sedona with pyspark") \
    .master("local[*]") \
    .config("spark.driver.memory", "9g") \
    .config('spark.jars', jar_path). \
    getOrCreate()

# create a sedona context
sedona = SedonaContext.create(config)
```


## Create a sedona session with internet

If you have internet access, you can use a maven url to specify which jar package you need

```shell

# build a sedona session (sedona = 1.5.1)
config = SedonaContext.builder() \
    .appName("Sedona with pyspark") \
    .master("local[*]") \
    .config("spark.driver.memory", "9g") \
    .config('spark.jars.packages',
            'com.acervera.osm4scala:osm4scala-spark3-shaded_2.12:1.0.11,' 
            'org.apache.sedona:sedona-spark-shaded-3.0_2.12:1.4.1,' 
            'org.datasyslab:geotools-wrapper:1.4.0-28.2'). \
     getOrCreate()

# create a sedona context
sedona = SedonaContext.create(config)
```